{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from keras.layers import Dense, Dropout, Activation, LSTM, Convolution1D, MaxPooling1D, Flatten\n",
    "# from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from torchbearer import Trial\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchbearer\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchbearer import Trial\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 D 中的卷没有标签。\n",
      " 卷的序列号是 14DF-F7F4\n",
      "\n",
      " D:\\git\\Stock-Market-Price-Prediction-master 的目录\n",
      "\n",
      "2019/07/21  18:38    <DIR>          .\n",
      "2019/07/21  18:38    <DIR>          ..\n",
      "2019/07/20  14:17    <DIR>          .ipynb_checkpoints\n",
      "2019/07/20  14:17           368,007 ^DJI.csv\n",
      "2019/07/20  14:17           104,540 ^GSPC.csv\n",
      "2019/07/20  14:17           167,205 ^GSPC_2011_06_01-2019_06_01.csv\n",
      "2019/07/20  14:17    <DIR>          __pycache__\n",
      "2019/07/20  14:17            41,117 1d_conv.weights\n",
      "2019/07/20  14:17           382,435 5_1_CNN-Copy1.ipynb\n",
      "2019/07/20  14:17           335,219 Archive.zip\n",
      "2019/07/20  14:17               658 CBOE yearly 04-18.csv\n",
      "2019/07/20  14:17    <DIR>          data\n",
      "2019/07/20  14:17           189,414 EUR_GBP 05-16.csv\n",
      "2019/07/20  14:17           189,007 EUR_JPY 05-16.csv\n",
      "2019/07/20  14:17           189,396 EUR_USD 05-16.csv\n",
      "2019/07/20  14:17           189,370 GBP_JPY 05-16.csv\n",
      "2019/07/20  14:17           189,425 GBP_USD 05-16.csv\n",
      "2019/07/20  14:17             8,500 misc_functions.py\n",
      "2019/07/20  14:17    <DIR>          MNIST\n",
      "2019/07/20  14:17             1,137 README.md\n",
      "2019/07/20  14:17           206,054 SP500 05-16.csv\n",
      "2019/07/21  18:38            64,318 stock_conditional_TS.ipynb\n",
      "2019/07/20  14:17           126,560 stock_conv1d.ipynb\n",
      "2019/07/20  14:17           136,934 stock_conv1d-Copy1.ipynb\n",
      "2019/07/20  14:17            70,938 stock_conv1d-out-of-sample.ipynb\n",
      "2019/07/21  18:31           211,812 stock_conv1d-pytorch.ipynb\n",
      "2019/07/20  14:17           162,338 stock_dilatedconv+lstm.ipynb\n",
      "2019/07/21  10:48             9,467 stock_lstm+conv1d.ipynb\n",
      "2019/07/20  14:17            58,239 stock_nn.ipynb\n",
      "2019/07/20  14:17            63,055 stock_rnn_lstm.ipynb\n",
      "2019/07/20  14:17             1,562 vanillabackprop.py\n",
      "2019/07/20  14:17           183,293 Volatility 05-16.csv\n",
      "              26 个文件      3,650,000 字节\n",
      "               6 个目录 204,099,723,264 可用字节\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\git\\\\Stock-Market-Price-Prediction-master\\\\data'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = os.path.join(os.getcwd(), 'data')\n",
    "datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 D 中的卷没有标签。\n",
      " 卷的序列号是 14DF-F7F4\n",
      "\n",
      " D:\\git\\Stock-Market-Price-Prediction-master\\data 的目录\n",
      "\n",
      "2019/07/20  14:17    <DIR>          .\n",
      "2019/07/20  14:17    <DIR>          ..\n",
      "2019/07/20  14:17           178,424 ^TNX.csv\n",
      "2019/07/20  14:17           193,366 ^VIX.csv\n",
      "2019/07/20  14:17               658 CBOE yearly 04-18.csv\n",
      "2019/07/20  14:17           189,414 EUR_GBP 05-16.csv\n",
      "2019/07/20  14:17           189,007 EUR_JPY 05-16.csv\n",
      "2019/07/20  14:17           189,396 EUR_USD 05-16.csv\n",
      "2019/07/20  14:17           189,370 GBP_JPY 05-16.csv\n",
      "2019/07/20  14:17           189,425 GBP_USD 05-16.csv\n",
      "2019/07/20  14:17           206,054 SP500 05-16.csv\n",
      "               9 个文件      1,525,114 字节\n",
      "               2 个目录 204,099,723,264 可用字节\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOE yearly 04-18.csv \n",
      "    Change Date     Rate (%)\n",
      "32   13-Dec-17  1.25 - 1.50\n",
      "33   21-Mar-18  1.50 - 1.75\n",
      "34   13-Jun-18  1.75 - 2.00\n",
      "35   26-Sep-18  2.00 - 2.25\n",
      "36   19-Dec-18  2.25 - 2.50\n",
      "EUR_GBP 05-16.csv \n",
      "               Date   Price    Open    High     Low Change %\n",
      "3125  Jan 07, 2005  0.6981  0.7022  0.7049  0.6971   -0.64%\n",
      "3126  Jan 06, 2005  0.7026  0.7041  0.7055  0.7016   -0.24%\n",
      "3127  Jan 05, 2005  0.7043  0.7049  0.7073  0.7021   -0.17%\n",
      "3128  Jan 04, 2005  0.7055  0.7069  0.7076  0.7044   -0.20%\n",
      "3129  Jan 03, 2005  0.7069  0.7058  0.7097  0.7038   -0.01%\n",
      "EUR_JPY 05-16.csv \n",
      "               Date   Price    Open    High     Low Change %\n",
      "3125  Jan 07, 2005  136.80  138.23  138.74  136.44   -1.16%\n",
      "3126  Jan 06, 2005  138.41  138.03  138.69  137.85    0.28%\n",
      "3127  Jan 05, 2005  138.03  138.85  139.02  137.68   -0.58%\n",
      "3128  Jan 04, 2005  138.83  138.34  139.05  137.77    0.38%\n",
      "3129  Jan 03, 2005  138.31  139.07  139.31  138.06   -0.40%\n",
      "EUR_USD 05-16.csv \n",
      "               Date   Price    Open    High     Low Change %\n",
      "3125  Jan 07, 2005  1.3054  1.3171  1.3251  1.3024   -0.89%\n",
      "3126  Jan 06, 2005  1.3171  1.3262  1.3286  1.3156   -0.69%\n",
      "3127  Jan 05, 2005  1.3262  1.3282  1.3305  1.3215   -0.08%\n",
      "3128  Jan 04, 2005  1.3272  1.3466  1.3496  1.3249   -1.42%\n",
      "3129  Jan 03, 2005  1.3463  1.3547  1.3582  1.3386   -0.70%\n",
      "GBP_JPY 05-16.csv \n",
      "               Date   Price    Open    High     Low Change %\n",
      "3125  Jan 07, 2005  195.99  196.83  197.30  195.37   -0.52%\n",
      "3126  Jan 06, 2005  197.01  195.99  197.40  195.78    0.54%\n",
      "3127  Jan 05, 2005  195.96  196.93  197.04  195.53   -0.42%\n",
      "3128  Jan 04, 2005  196.78  195.69  197.08  195.05    0.60%\n",
      "3129  Jan 03, 2005  195.61  197.04  197.18  195.31   -0.45%\n",
      "GBP_USD 05-16.csv \n",
      "               Date   Price    Open    High     Low Change %\n",
      "3125  Jan 07, 2005  1.8699  1.8755  1.8867  1.8648   -0.27%\n",
      "3126  Jan 06, 2005  1.8750  1.8828  1.8857  1.8695   -0.42%\n",
      "3127  Jan 05, 2005  1.8830  1.8838  1.8903  1.8727    0.04%\n",
      "3128  Jan 04, 2005  1.8822  1.9045  1.9085  1.8781   -1.16%\n",
      "3129  Jan 03, 2005  1.9043  1.9199  1.9205  1.8981   -0.75%\n",
      "SP500 05-16.csv \n",
      "             Date        Price         Open         High          Low  \\\n",
      "3016  2016/12/23  2263.790039  2260.250000  2263.790039  2258.840088   \n",
      "3017  2016/12/27  2268.879883  2266.229980  2273.820068  2266.149902   \n",
      "3018  2016/12/28  2249.919922  2270.229980  2271.310059  2249.110107   \n",
      "3019  2016/12/29  2249.260010  2249.500000  2254.510010  2244.560059   \n",
      "3020  2016/12/30  2238.830078  2251.610107  2253.580078  2233.620117   \n",
      "\n",
      "          Volume  \n",
      "3016  2020550000  \n",
      "3017  1987080000  \n",
      "3018  2392360000  \n",
      "3019  2336370000  \n",
      "3020  2670900000  \n",
      "^TNX.csv \n",
      "             Date   Open   High    Low  Close  Adj Close  Volume\n",
      "3016  2016-12-23  2.541  2.545  2.526  2.543      2.543     0.0\n",
      "3017  2016-12-27  2.552  2.576  2.550  2.563      2.563     0.0\n",
      "3018  2016-12-28  2.560  2.563  2.503  2.506      2.506     0.0\n",
      "3019  2016-12-29  2.486  2.497  2.460  2.477      2.477     0.0\n",
      "3020  2016-12-30  2.474  2.483  2.432  2.446      2.446     0.0\n",
      "^VIX.csv \n",
      "             Date   Open   High    Low  Close  Adj Close  Volume\n",
      "3016  2016-12-23  11.38  11.81  11.35  11.44      11.44       0\n",
      "3017  2016-12-27  12.26  12.33  11.84  11.99      11.99       0\n",
      "3018  2016-12-28  11.89  13.04  11.85  12.95      12.95       0\n",
      "3019  2016-12-29  13.15  13.71  12.95  13.37      13.37       0\n",
      "3020  2016-12-30  13.20  14.68  13.05  14.04      14.04       0\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i, file in enumerate(os.listdir(datapath)):\n",
    "    data.append(pd.read_csv(os.path.join(datapath,file))) \n",
    "for i in range(len(data)):\n",
    "    print(os.listdir(datapath)[i], '\\n', data[i].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "3130\n",
      "3130\n",
      "3130\n",
      "3130\n",
      "3130\n",
      "3021\n",
      "3021\n",
      "3021\n"
     ]
    }
   ],
   "source": [
    "#TNX: COBE 10 years interest rate\n",
    "#VIX: COBE volitility index\n",
    "for i in range(len(data)):\n",
    "    print(len(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3021, 4)\n",
      "(3021, 4)\n",
      "(3021, 4)\n"
     ]
    }
   ],
   "source": [
    "# take TNX, VIX and SP500 and prepocessing\n",
    "sp500 = data[-3]\n",
    "tnx = data[-2]\n",
    "vix = data[-1]\n",
    "\n",
    "#take only some columns\n",
    "sp500= sp500.values[:, 1:5]\n",
    "print (sp500.shape)\n",
    "tnx= tnx.values[:, 1:5]\n",
    "print (tnx.shape)\n",
    "vix= vix.values[:, 1:5]\n",
    "print (vix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1202.079956 1211.920044 1217.800049 1200.319946]\n",
      " [1188.050049 1202.079956 1205.839966 1185.390015]\n",
      " [1183.73999 1188.050049 1192.72998 1183.719971]\n",
      " ...\n",
      " [2249.919922 2270.22998 2271.310059 2249.110107]\n",
      " [2249.26001 2249.5 2254.51001 2244.560059]\n",
      " [2238.830078 2251.610107 2253.580078 2233.6201170000004]]\n"
     ]
    }
   ],
   "source": [
    "print(sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3020, 4) (3, 3020)\n"
     ]
    }
   ],
   "source": [
    "# split sample X and target y\n",
    "X = np.zeros((3, 3020, 4))\n",
    "X[0,:,:] = sp500[:3020, :]\n",
    "X[1,:,:] = tnx[:3020, :]\n",
    "X[2,:,:] = vix[:3020, :]\n",
    "\n",
    "y = np.zeros((3,3020))\n",
    "y[0,:] = sp500[1:, 3]\n",
    "y[1,:] = tnx[1:, 3]\n",
    "y[2,:] = vix[1:, 3]\n",
    " \n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = int(3020*0.8)\n",
    "# X = np.zeros((3, 3020, 4)) \n",
    "# y = np.zeros((3,3020))\n",
    "# for i, data in enumerate([sp500, tnx, vix]):\n",
    "#     train = data[:a]\n",
    "#     test = data[a:]\n",
    "#     train = (train- np.min(train, axis = 0))/(np.max(train,axis=0)- np.min(train, axis=0))\n",
    "#     test = (test- np.min(test,axis=0))/(np.max(test,axis=0)- np.min(test,axis=0))\n",
    "# #     print(train.shape, test.shape)\n",
    "#     data = np.concatenate((train,test), axis=0)\n",
    "# #     print(i, data.shape)\n",
    "#     X[i,:,:] = data[:3020, :]\n",
    "#     y[i,:] = data[1:, 3]\n",
    "    \n",
    "# print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3020, 3) (3020,)\n"
     ]
    }
   ],
   "source": [
    "temp1 = X[0, :, 0]\n",
    "temp2 = X[1, :, 3]\n",
    "temp3 = X[2, :, 3]\n",
    "X_temp = np.array([temp1, temp2, temp3]).T\n",
    "X = X_temp\n",
    "\n",
    "y = y[0,:]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1202.079956 1188.050049 1183.73999  ... 2268.879883 2249.919922\n",
      " 2249.26001 ] [4.22  4.283 4.277 ... 2.563 2.506 2.477] [14.08 13.98 14.09 ... 11.99 12.95 13.37]\n",
      "[[1202.079956    4.22       14.08    ]\n",
      " [1188.050049    4.283      13.98    ]\n",
      " [1183.73999     4.277      14.09    ]\n",
      " ...\n",
      " [2268.879883    2.563      11.99    ]\n",
      " [2249.919922    2.506      12.95    ]\n",
      " [2249.26001     2.477      13.37    ]] [1185.390015 1183.719971 1183.27002  ... 2249.110107 2244.560059\n",
      " 2233.620117]\n"
     ]
    }
   ],
   "source": [
    "print(temp1, temp2, temp3)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3020, 3) (3020,)\n"
     ]
    }
   ],
   "source": [
    "y= (y- min(y))/(max(y)- min(y)) #??? normalsation\n",
    "X= (X- np.min(X,axis=0))/(np.max(X, axis=0)-np.min(X,axis=0))\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2921, 100, 3) (2921,)\n"
     ]
    }
   ],
   "source": [
    "time_steps= 100 #1 to 100 days ahead\n",
    "X_new= np.zeros((X.shape[0] - time_steps +1, 100, X.shape[1]))\n",
    "y_new= np.zeros((y.shape[0] -time_steps +1,))\n",
    "for ix in range(X_new.shape[0]):\n",
    "    for jx in range(time_steps):\n",
    "        X_new[ix, jx, :]= X[ix +jx, :]\n",
    "    y_new[ix]= y[ix + time_steps -1]\n",
    "print (X_new.shape, y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2416, 100, 3) (2416,)\n",
      "(505, 100, 3) (505,)\n"
     ]
    }
   ],
   "source": [
    "# split train/test\n",
    "split = int(0.8*X.shape[0])\n",
    "X_train = X_new[:split]\n",
    "X_test = X_new[split:]\n",
    "\n",
    "y_train = y_new[:split]\n",
    "y_test = y_new[split:]\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalisation after split the train/test\n",
    "# for i in range(3):\n",
    "#     y_train[:,i]= (y_train[:,i]- min(y_train[:,i]))/(max(y_train[:,i])- min(y_train[:,i]))\n",
    "#     X_train[:,i,:,:]= (X_train[:,i,:,:]- np.min(X_train[:,i,:,:],axis=0))/(np.max(X_train[:,i,:,:], axis=0)-np.min(X_train[:,i,:,:],axis=0))\n",
    "\n",
    "#     y_test[:,i]= (y_test[:,i]- min(y_test[:,i]))/(max(y_test[:,i])- min(y_test[:,i]))\n",
    "#     X_test[:,i,:,:]= (X_test[:,i,:,:]- np.min(X_test[:,i,:,:],axis=0))/(np.max(X_test[:,i,:,:], axis=0)-np.min(X_test[:,i,:,:],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 86, 1]           2,944\n",
      "            Conv2d-2            [-1, 32, 70, 1]          30,752\n",
      "            Linear-3                    [-1, 1]           2,177\n",
      "================================================================\n",
      "Total params: 35,873\n",
      "Trainable params: 35,873\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 0.20\n",
      "----------------------------------------------------------------\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(15, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(64, 32, kernel_size=(15, 1), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=2176, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Network model\n",
    "from torchsummary import summary\n",
    "    \n",
    "class Net(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size = (15, 3), padding=0)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size = (15, 1), padding=0)\n",
    "        self.fc1 = nn.Linear(2176 , 1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.max_pool2d(out, kernel_size = (3, 1), stride=(1, 1))\n",
    "        out = self.conv2(out)\n",
    "        out = F.max_pool2d(out, kernel_size = (3, 1), stride=(1, 1))\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc1(out)\n",
    "#         out = F.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)\n",
    "\n",
    "\n",
    "# summary(your_model, input_size=(channels, H, W))\n",
    "summary(model,(1, 100, 3))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2416, 100, 3]) torch.Size([2416]) torch.Size([505, 100, 3])\n"
     ]
    }
   ],
   "source": [
    "#convert to torch\n",
    "trainData = torch.from_numpy(X_train)\n",
    "testData = torch.from_numpy(y_train)\n",
    "validateData = torch.from_numpy(X_test)\n",
    "print(trainData.shape, testData.shape, validateData.shape)\n",
    "# testData = testData.view(testData.shape[0],3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2416, 1, 100, 3]) torch.Size([2416, 1]) torch.Size([505, 1, 100, 3])\n"
     ]
    }
   ],
   "source": [
    "trainData = trainData.view(2416,-1,100,3)\n",
    "testData = testData.view(2416,-1)\n",
    "\n",
    "validateData = validateData.view(validateData.shape[0],-1,100,3)\n",
    "print(trainData.shape,testData.shape,validateData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 3]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "train = TensorDataset(trainData, testData)\n",
    "# print(train[0])\n",
    "tr, te = train[0]\n",
    "print(tr.shape, te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([256, 1, 100, 3])\n",
      "torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "#train loader\n",
    "trainloader = DataLoader(train, batch_size=256, shuffle=True)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images)) \n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4743,    nan, 0.2152],\n",
       "          [0.4960,    nan, 0.1839],\n",
       "          [0.5016,    nan, 0.1644],\n",
       "          ...,\n",
       "          [0.4912,    nan, 0.1506],\n",
       "          [0.5065,    nan, 0.1209],\n",
       "          [0.5140,    nan, 0.1227]]],\n",
       "\n",
       "\n",
       "        [[[0.4424,    nan, 0.0108],\n",
       "          [0.4467,    nan, 0.0094],\n",
       "          [0.4393,    nan, 0.0128],\n",
       "          ...,\n",
       "          [0.4548,    nan, 0.0662],\n",
       "          [0.4604,    nan, 0.0476],\n",
       "          [0.4755,    nan, 0.0324]]],\n",
       "\n",
       "\n",
       "        [[[0.4046,    nan, 0.0874],\n",
       "          [0.4091,    nan, 0.0817],\n",
       "          [0.4111,    nan, 0.0854],\n",
       "          ...,\n",
       "          [0.4038,    nan, 0.0934],\n",
       "          [0.4157,    nan, 0.0843],\n",
       "          [0.4146,    nan, 0.0869]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.3880,    nan, 0.0355],\n",
       "          [0.3893,    nan, 0.0331],\n",
       "          [0.3923,    nan, 0.0247],\n",
       "          ...,\n",
       "          [0.4596,    nan, 0.0317],\n",
       "          [0.4616,    nan, 0.0297],\n",
       "          [0.4611,    nan, 0.0285]]],\n",
       "\n",
       "\n",
       "        [[[0.6117,    nan, 0.0707],\n",
       "          [0.6057,    nan, 0.0852],\n",
       "          [0.6146,    nan, 0.0686],\n",
       "          ...,\n",
       "          [0.7278,    nan, 0.0420],\n",
       "          [0.7282,    nan, 0.0423],\n",
       "          [0.7308,    nan, 0.0317]]],\n",
       "\n",
       "\n",
       "        [[[0.4225,    nan, 0.1230],\n",
       "          [0.4149,    nan, 0.1491],\n",
       "          [0.4146,    nan, 0.1332],\n",
       "          ...,\n",
       "          [0.4710,    nan, 0.0800],\n",
       "          [0.4714,    nan, 0.0854],\n",
       "          [0.4657,    nan, 0.0940]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "# define the loss function and the optimiser\n",
    "loss_function = nn.MSELoss()\n",
    "optimiser = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01f1e96c1aa406da29b90400d6e2263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='0/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da841f1dc4f45f89c2fa5dd1b971ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c27bd772f4f4e25be90732d1ca4247b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2d5c1c2073459c9862d4dc6d8f5393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='3/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2f9976bdcf43c2a8fa14c43aa60069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='4/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3066cb573f6f46fdb2c7792cd161aa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='5/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b5bb97a0d74e95bfcb8c6d450b8bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='6/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37dbfbc10ef4e2ca9c3fdf775ca13e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='7/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ac7361387b4fb8a6e115486ab9f327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='8/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb7dee4024642bbb8bf42260502433d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='9/10(t)', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[((10, None), {}),\n",
       " ((10, None), {}),\n",
       " ((10, None), {}),\n",
       " ((10, None), {}),\n",
       " ((10, None), {}),\n",
       " ((10, None), {}),\n",
       " ((10, None), {}),\n",
       " ((10, None), {}),\n",
       " ((10, None), {}),\n",
       " ((10, None), {})]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch method for training\n",
    "print(device)\n",
    "trial = Trial(model, optimiser, loss_function).to(device)\n",
    "trial.with_generators(trainloader)\n",
    "trial.run(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([505, 1])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred= model(validateData.float().to(device))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_pred.cpu().detach().numpy(), 'r-')\n",
    "plt.plot(y_test, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
