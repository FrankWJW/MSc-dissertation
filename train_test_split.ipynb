{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "utility function:\n",
    "\n",
    "Spliting train and test + normalisation + making window\n",
    "\n",
    "input:  data, target, len_of_trainset, time_interval\n",
    "\n",
    "output: trainData, testData, validateData\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from keras.layers import Dense, Dropout, Activation, LSTM, Convolution1D, MaxPooling1D, Flatten\n",
    "# from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from torchbearer import Trial\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchbearer\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchbearer import Trial\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class utility_fun():\n",
    "    \n",
    "    \n",
    "    def __init__(data, len_of_trainset = 2412, time_interval = 100):\n",
    "        print(start)\n",
    "        self.X = data[0]\n",
    "        self.y = data[1]\n",
    "        self.len_of_trainset = len_of_trainset\n",
    "        self.time_interval = time_interval\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "    def norm(self):\n",
    "        \n",
    "        y1 = self.y[:len_of_trainset]\n",
    "        y2 = self.y[len_of_trainset:]\n",
    "\n",
    "        X1 = self.X[:len_of_trainset,:]\n",
    "        X2 = self.X[len_of_trainset:,:]\n",
    "        \n",
    "        X1= (X1- np.min(X1,axis=0))/(np.max(X1, axis=0)-np.min(X1,axis=0))\n",
    "        X2= (X2- np.min(X2,axis=0))/(np.max(X2, axis=0)-np.min(X2,axis=0))\n",
    "\n",
    "        self.X = np.concatenate((X1,X2) , axis = 0)\n",
    "        self.y = np.concatenate((y1,y2) , axis = 0)\n",
    "#         print(self.X.shape, self.y.shape)\n",
    "        \n",
    "    def sepera_time_step(self):\n",
    "        time_steps= self.time_interval\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        X_new= np.zeros((X.shape[0] - time_steps +1, time_steps, X.shape[1]))\n",
    "        y_new= np.zeros((y.shape[0] -time_steps +1,))\n",
    "        for ix in range(X_new.shape[0]):\n",
    "            for jx in range(time_steps):\n",
    "                X_new[ix, jx, :]= X[ix +jx, :]\n",
    "            y_new[ix]= y[ix + time_steps -1]\n",
    "#         print (X_new.shape, y_new.shape)\n",
    "        self.X = X_new\n",
    "        self.y = y_new\n",
    "        \n",
    "    def test_train_split(self):\n",
    "        split = len_of_trainset\n",
    "#         X_train = X_new[:split]\n",
    "#         X_test = X_new[split:]\n",
    "        \n",
    "        X_train = self.X[:split]\n",
    "        X_test = self.X[split:]\n",
    "\n",
    "        y_train = self.y[:split]\n",
    "        y_test = self.y[split:]\n",
    "\n",
    "#         print (X_train.shape, y_train.shape)\n",
    "#         print (X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "    def build_dataloader(self):\n",
    "        #convert to torch\n",
    "        trainData = torch.from_numpy(self.X_train)\n",
    "        testData = torch.from_numpy(self.y_train)\n",
    "        validateData = torch.from_numpy(self.X_test)\n",
    "        \n",
    "        lens = self.len_of_trainset\n",
    "        time_steps = self.time_interval\n",
    "        \n",
    "        \n",
    "        trainData = trainData.view(lens,-1,time_steps,3)\n",
    "        testData = testData.view(lens,-1)\n",
    "        validateData = validateData.view(validateData.shape[0],-1,time_steps,3)\n",
    "        print(trainData.shape,testData.shape,validateData.shape)\n",
    "        \n",
    "        train = TensorDataset(trainData.view(lens, -1).float(), testData.view(-1).float())\n",
    "        trainloader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "        \n",
    "        return trainloader, validateData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
